{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using CNN-LSTM to classify violent clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# The video should be converted to frames first. During training, three frames are extracted per second,\n",
    "# each frame is resized to 64x64 pixels, and the LSTM layer takes 10 consecutive frames as input.\n",
    "def preprocess_video(video_path, frame_count=10, frame_size=(64, 64)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while len(frames) < frame_count:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, frame_size)\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    \n",
    "    if len(frames) == 0:\n",
    "        return np.zeros((frame_count, frame_size[0], frame_size[1], 3))\n",
    "    elif len(frames) < frame_count:\n",
    "        frames.extend([np.zeros_like(frames[0])]*(frame_count - len(frames)))\n",
    "    return np.array(frames)\n",
    "\n",
    "def load_test_data(folder_path, frame_count=10, frame_size=(64, 64)):\n",
    "    test_data = []\n",
    "    video_files = [f for f in os.listdir(folder_path) if f.endswith('.mp4') or f.endswith('.avi')]\n",
    "    for video_file in video_files:\n",
    "        video_path = os.path.join(folder_path, video_file)\n",
    "        frames = preprocess_video(video_path, frame_count, frame_size)\n",
    "        test_data.append(frames)\n",
    "    return np.array(test_data), video_files\n",
    "\n",
    "# Folder containing your test videos\n",
    "test_video_folder = \"D:/Yolo/test/result\"\n",
    "test_data, test_video_files = load_test_data(test_video_folder)\n",
    "test_data = test_data / 255.0\n",
    "\n",
    "# This model can achieve over 90% accuracy on the training set and 77% on the validation set.\n",
    "model_path = \"D:/CNN-LSTM/models/violence_detection_model_conv_64_lstm_64.h5\"\n",
    "model = tf.keras.models.load_model(model_path, compile=False)\n",
    "\n",
    "# Recompile the model with a compatible optimizer and loss function\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "predictions = model.predict(test_data)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "class_names = [\"high-level violence\", \"low-level violence\", \"non-violence\"]\n",
    "for video_file, predicted_class in zip(test_video_files, predicted_classes):\n",
    "    print(f\"Video: {video_file}, Predicted Class: {class_names[predicted_class]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
